<!DOCTYPE 
HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        "http://www.w3.org/TR/1999/REC-html401-19991224/loose.dtd">
<html lang="en">   
<head>
  <title>ALTA 2011 Shared Task Description</title>
  <meta http-equiv="content-type" content="text/html; charset=iso-8859-1">
  <link rel="stylesheet" href="sharedtask.css" type="text/css">
</head>

<body>
<!-- This table contains the main structure of the page -->
<table width="100%" border="0" cellpadding="0" cellspacing="0" summary="This table contains the main structure">

  <tr valign="middle">
    <!-- Logo -->
    <td width="85" align="center"><a href="http://www.alta.asn.au"><img src="http://www.alta.asn.au/images/logo_sm.jpg" width="74" height="65" border="0" alt="ALTA logo"></a></td>
    <!-- Title -->
    <td width="100%" colspan="5" class="sitename" align="center">
Language Technology Programming Competition 2011</td>
  </tr>

  <tr valign="top">

<td width="15%">
 
<table width="100%" border="0" cellpadding="0" cellspacing="0" class="headerbar" summary="This table contains the top level navigation links">


  <tr>
    <td align="left" class = "headercell">
      <a class="headerlink" href="index.html">Home</a> 
    </td>
  </tr>

  <tr>
    <td align="left" class = "headercell">
      <a class="headerlink" href="description.html">Task Description</a>
    </td>
  </tr>

  <tr>
    <td align="left" class = "headercell">
      <a class="headerlink" href="info.html">Useful Information</a>
    </td>
  </tr>
  <tr>
    <td align="left" class = "headercell">
      <a class="headerlink" href="submission.html">Submission</a>
    </td> 
 </tr>


<tr><td>&nbsp;</td></tr>
</table>
<!-- End Macquarie navigation table -->
</td>

<td width="2%">&nbsp;</td>


<td width="53%">

<!-- END OF HEADER - DO NOT EDIT ABOVE THIS LINE - Document Id: "altw"  -->




<h2>2011 Shared Task Description</h2>

<h3>Basic Task Description</h3>

<p>June 21, 2011 | Version 1</p>

<p>The basic task is to build an automatic evidence grading system for
evidence-based medicine. Evidence-based medicine is a medical practice
which requires practitioners to search medical literature for evidence
when making clinical decisions. The practitioners are also required to
grade the quality of extracted evidence on some chosen scale. The goal
of the grading system is to automatically determine the grade of an
evidence given the article abstract(s) from which the evidence is
extracted.</p>

<p>You will be provided with: (1) a set of training documents; (2) a
set of development documents; and (3), closer to the submission
deadline, a set of test documents. For the training and development
sets, you will additionally have access to the evidence grades. For
the test documents, this will not be provided.</p>

<p>The grading scale used for this task is the Strength of
Recommendation Taxonomy (SORT). This taxonomy has 3 grades - A
(strong), B (moderate) and C (weak). The grade of an evidence depends
on multiple factors and information about this grading scale can be
found in the paper
by <a href="http://www.jabfm.org/cgi/content/short/17/1/59"
target="_blank">Ebell et al. (2004)</a> </p>

<p>The grades used for this task have been generated by medical
experts. Your task is to implement a grading system based on the
training and development datasets, to then run over the test documents
to determine the grade of each evidence.</p>

<h3>Data Files and Format</h3>

<p>The <strong>training and development</strong> sets will contain:</p>

<ol>
    <li>A text file containing the evidence IDs, a grade for each
    evidence and one or more abstract IDs for each evidence. The first
    few lines of this text file may look like this:</li>

    <blockquote><tt> 41711 B 10553790 15265350</tt> <br>
    <tt> 53581 C 12804123 16026213 14627885</tt>  <br>
    <tt> 53583 B 15213586 </tt> <br>
    <tt> 52401 A 15329425 9058342 11279767</tt></blockquote>
    
    <li>A zip file containing the abstracts. The abstracts will have
    file names of the form <tt>id.xml</tt>. For example, the first
    abstract of evidence <tt>41711</tt> (shown above) will have the
    name <tt>10553790.xml</tt>. All abstracts will be in
    the <tt>xml</tt> format used
    by <a href="http://www.ncbi.nlm.nih.gov/pubmed/"
    target="_blank">PubMed</a>.</li>

    <li>A python evaluation script (<tt>eval.py</tt>) which takes the
    following arguments:

   <ul>
        <li>Required arguments:
        <p> </p>
        <table cellpadding="3">
            <tbody>

                <tr>
                    <td align="left"><tt>-o FILENAME</tt></td>
                    <td align="left" valign="top">FILENAME contains the output of the system over a test dataset</td>
                </tr>
                <tr>
                    <td align="left"><tt>-g FILENAME</tt></td>
                    <td align="left" valign="top">FILENAME contains the gold standard</td>
                </tr>
            </tbody>
        </table>
        </li>
        <li>Optional arguments: 

        <p> </p>
        <table cellpadding="3">
            <tbody>
                <tr>
                    <td align="left"><tt>-e</tt></td>
                    <td align="left" valign="top">Outputs the IDs of the misclassified instances</td>
                </tr>
            </tbody>
        </table>
        </li>
    </ul>


<p>For example, if you run your system over the development set and
want to compare its accuracy against the gold standard for the
development set, the following command can be used:</p>

<blockquote><tt>python eval.py -o out.txt -g devtestset.txt -e</tt></blockquote>

<p>where <tt>out.txt</tt> is the output of your system
and <tt>devtestset.txt</tt> is the text file (that we will provide)
containing the evidence IDs and their grades.</p></li>

</ol>

<p>The <strong>test</strong> set will contain:</p>

<ol>

    <li>A text file containing the evidence IDs and one or more
    abstract IDs for each evidence. The first few lines may look like
    this:</li>

    <blockquote><tt> 41711 10553790 15265350</tt> <br>
    <tt> 53581 12804123 16026213 14627885</tt>  <br>
    <tt> 53583 15213586 </tt> <br>
    <tt> 52401 15329425 9058342 11279767</tt></blockquote>
    
    <li>A zip file containing the required abstracts.</li>
    </ol>

<h3>Submission</h3>

<p>The results of your evidence grading system should be submitted in
a single text file with each line containing:</p>

<ol>
<li>The evidence ID (e.g. <tt>41711</tt>)</li>
<li>The predicted grade for that evidence (i.e. <tt>A</tt>, <tt>B</tt>
or <tt>C</tt>)</li>
</ol>

<p>The first few lines of a submission file may look as follows:</p>

<blockquote><tt> 41711 B</tt> <br>
    <tt> 53581 C</tt>  <br>
    <tt> 53583 B</tt> <br>
    <tt> 52401 A</tt></blockquote>
    

<h3>Important Dates</h3>
<table cellpadding="3">
    <tbody>
        <tr>
            <td align="left">Release of training and development data</td>
            <td align="left">On registration</td>
        </tr>
        <tr>

            <td align="left">Release of test data (without annotations)</td>
            <td align="left">4 October 2011</td>
        </tr>
        <tr>
            <td align="left">Deadline for submission of results over test data</td>
            <td align="left">7 October 2011</td>
        </tr>
        <tr>
            <td align="left">Notification of results</td>
            <td align="left">12 October 2011</td>
        </tr>
        <tr>
            <td align="left">Deadline for submission of system description poster</td>
            <td align="left">28 October 2011</td>
        </tr>
    </tbody>
</table>

<h3>Results</h3>
<p>Here are the results of all participants who submitted a
poster. Each participant was allowed to submit up to three runs. The
evaluation meaure is the accuracy (number of correct classifications
divided by the total number of classifications). Since none of the
participants obtained results that were
statistically significantly better than the baseline, no prizes were
awarded.</p>

<h5>Baseline</h5>

<p>The baseline is a simple majority baseline: classify all elements with class "B". The results with 5% confidence intervals are:</p>

<ul>
  <li>Accuracy = 0.486 (0.415-0.558)
</ul>

<h5>Student Category</h5>

<ul>
  <li>University of Melbourne [<a href="UMelbourne.pdf">poster</a>]</li>
    <ol>
      <li>Accuracy = 0.486</li>
      <li>Accuracy = 0.426</li>
    </ol>
</ul>

<h5>Open Category</h5>

<ul>
  <li>UAB_NLP [<a href="UAB_NLP.pdf">poster</a>]</li>
    <ol>
      <li>Accuracy = 0.437
    </ol>
</ul>

<h3>Publications</h3>

<ul>
  <li>Diego Molla, Abeed Sarker. <a href="http://www.alta.asn.au/events/alta2011/proceedings/pdf/U11-1003.pdf">Automatic Grading of Evidence: the
  2011 ALTA Shared Task</a> (2011). Proceedings of the 2011 Australasian
  Language Technology Workshop, Canberra.</li>
</ul>

<!-- End of body content -->  </td>
 <td width="2%"> </td>
 <td width="28%"><br>

<tr>
<td colspan="6">

<!-- Logos -->

<!-- ----- FOOTER - DO NOT EDIT BEYOND THIS LINE ----- -->


</td>

<td width="2%">&nbsp;</td>

</tr>
</table>
<!-- End of main table -->

<!-- Start of footer -->
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<!-- <td class="footertext"> 
<td>
For any comments or questions about these pages please contact the
ALTA Workshop 2010
organisers (altw2010 AT gmail DOT com)
<p></p> -->
</td>
</tr>
</table>
<!-- End of footer -->
<hr>
&copy; ALTA 2011. <a href="mailto:shared.task@alta.asn.au">Competition
Organisers</a>.
</body>
</html>
